{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTEAism/cr+VKSOMJH+rek",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vaani64/Deep_Learning_Codes/blob/main/Implementation_of_a_Restricted_Boltzmann_Machine_(RBM)_that_demonstrates_stacking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODnyx5hMZwAm",
        "outputId": "2e69c4e7-6a5f-485c-e56c-fdd70102671c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting unsupervised pretraining with RBMs...\n",
            "Training RBM layer 1/2...\n",
            "Training RBM layer 2/2...\n",
            "Starting supervised fine-tuning with Logistic Regression...\n",
            "Test Accuracy: 85.00%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate synthetic dataset\n",
        "def generate_data(samples=1000, features=50):\n",
        "    np.random.seed(42)\n",
        "    X = np.random.rand(samples, features) > 0.5  # Random binary data\n",
        "    y = (np.sum(X, axis=1) > (features / 2)).astype(int)  # Binary label: 1 if sum of features > features/2\n",
        "    return X, y\n",
        "\n",
        "# Train stacked RBMs\n",
        "class StackedRBMs:\n",
        "    def __init__(self, rbm_layers, rbm_learning_rate=0.1, rbm_n_iter=10):\n",
        "        # Create a list of RBM layers\n",
        "        self.rbms = [\n",
        "            BernoulliRBM(n_components=n_components, learning_rate=rbm_learning_rate, n_iter=rbm_n_iter)\n",
        "            for n_components in rbm_layers\n",
        "        ]\n",
        "        self.logistic_regression = LogisticRegression()\n",
        "\n",
        "    def pretrain(self, X):\n",
        "        print(\"Starting unsupervised pretraining with RBMs...\")\n",
        "        current_input = X\n",
        "        for idx, rbm in enumerate(self.rbms):\n",
        "            print(f\"Training RBM layer {idx + 1}/{len(self.rbms)}...\")\n",
        "            rbm.fit(current_input)  # Train the RBM\n",
        "            current_input = rbm.transform(current_input)  # Use transformed data as input for next RBM\n",
        "\n",
        "    def fine_tune(self, X, y):\n",
        "        print(\"Starting supervised fine-tuning with Logistic Regression...\")\n",
        "        # Pass data through all RBMs\n",
        "        for rbm in self.rbms:\n",
        "            X = rbm.transform(X)\n",
        "        self.logistic_regression.fit(X, y)  # Train logistic regression on the transformed features\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Pass data through all RBMs\n",
        "        for rbm in self.rbms:\n",
        "            X = rbm.transform(X)\n",
        "        return self.logistic_regression.predict(X)  # Use logistic regression for final prediction\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate data\n",
        "    X, y = generate_data()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define RBM stacking parameters\n",
        "    rbm_layers = [128, 64]  # Two RBMs with 128 and 64 hidden units respectively\n",
        "\n",
        "    # Initialize Stacked RBMs\n",
        "    stacked_rbm = StackedRBMs(rbm_layers=rbm_layers, rbm_learning_rate=0.05, rbm_n_iter=15)\n",
        "\n",
        "    # Pretraining (unsupervised)\n",
        "    stacked_rbm.pretrain(X_train)\n",
        "\n",
        "    # Fine-tuning (supervised)\n",
        "    stacked_rbm.fine_tune(X_train, y_train)\n",
        "\n",
        "    # Evaluate model\n",
        "    y_pred = stacked_rbm.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    }
  ]
}